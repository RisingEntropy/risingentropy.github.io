---
title: 期望与概率
date: 2019-04-05 12:00:57 +0800
image: '/images/posts/OI.png'
tags: [OI, former blog]
---

# 期望与概率
#  一些概念
#  基本事件ω(也称样本点)： 
一次试验可能出现的每一个直接的结果。也就是随机试验不能够再分解的结果。如：
E1有两个基本事件：E1 ={出现正面}， E2={出现反面}
E2有六个基本事件： Ei ={出现 i 点}，i=1,2,3,4,5,6
#  样本空间Ω：全体基本事件的集合。如：
E2的样本空间为 Ω={1，2，3，4，5，6}
#  随机事件：
试验的每一个可能结果。用大写字母A,B,C等表示随机事件也就是样本空间的子集，即若干基本事件组成的集合。如：在E2中，“出现偶数点”的事件可表示为A= {2，4，6}
#  事件发生：
当事件A所包含的基本事件有一个出现，就说事件A发生了，否则就说事件A未发生

 -  必然事件：一定发生的事件，也就是样本空间Ω 
 -  不可能事件：一定不发生的事件，记为Φ
 -  事件包含：如果事件A发生必然导致事件B发生．则称事件B包含事件A，记作 A⊂ B 或 B ⊃ A
 -  事件的和：事件A与事件B至少有一个发生，这样的一个事件称为事件A 与事件B的和或并，记为A U B 或 A + B 
 -  事件的积：事件A与事件B同时发生，这样的事件称为事件A与事件B的积或交，记为A∩B 或 AB
 -  事件的和与积可以推广到多个事件

#  事件的差：
事件A 发生而事件B不发生，这样的事件称为事件A与事件B的差，记为A-B。如A={2,4,6}，B={2,3}，则A-B={4,6}。 A-B就是A的基本事件中去掉含在B中的，余下的基本事件组成的事件。
#  互斥事件：
若事件A与事件B不能同时发生(即AB=Φ)，则称事件A与事件B为互不相容或互斥。若A与B互不相容，就是A与B不含有公共的基本事件
#  对立事件(互逆)：
若事件A与事件B有且仅有一个发生，且AUB=Ω，A∩B=Φ，称事件A与事件B互为对立事件或互逆事件，
其中事件B叫做事件A 的逆事件，记作$B=\overline{A}$，事件B叫做事件A的逆事件，记作$A=\overline{B}$
# 概率公理
样本空间 S 是一个集合，它的元素称为基本事件。样本空间的一个子集被称为事件
根据定义，所有基本事件互斥。
概率：如果有一种事件到实数的映射 P{}，满足：

 1. 目对任何事件 A， P{A}≥0
 2. P{S}=1
 3. 对两个互斥事件， P{A∪B}=P{A}+P{B}


则可称 P{A}为事件 A 的概率。上述三条称为概率公理。
# 条件概率
定义 设E为一试验，A和B为E中两事件，且$P(A)>0$，则称$P(AB)/P(A)$为事件A发生的条件下事件B发生的条件概率，记作$P(B|A)$，即$P(B|A)= P(AB)/P(A) $,其中，P(AB)并不能简单的认为是$P(A)*P(B)$，而是把AB看做一起的事件看做整体计算。
eg：
袋中有5个球，2个黑球，3个白球，现依次取两球且不放回，(1)求第二次取到黑球的概率，(2)若已知第一次取到黑球的条件下，求第二次取到黑球的概率
显然，B|A第一次取到黑球的条件下，求第二次取到黑球的概率，A事件是第一次取到黑球的事件，B是两次都取到黑球的事件。概率：
$$A:\frac{2}{5}$$
$$AB:\frac{A^2_2}{A_5^2}$$
$$Therefore$$
$$P(A|B) = \frac{P(AB)}{P(A)} = \frac{\frac{A^2_2}{A_5^2}}{\frac{2}{5}} = \frac{1}{4}$$
# 全概率公式
定义 设试验E的样本空间为Ω，事件A1,A2,……,An满足：
1、两两互不相容
2、ΣAi= Ω
3、P(Ai)>0
则称A1,A2,……,An 为 Ω 的一个划分(分割)定理 设 Ω为试验 E 的样本空间，A 为 E 的一个随机事件，B1,B2,……,Bn 为Ω的一个划分，且有 P(Bi)>0，则
$P(A) = \sum_{i=1}^{n}P(B_i)P(A|B_i)$
证明：
$P(A)=\sum_{i=1}^n P(AB_i) = P(A) = \sum_{i=1}^{n}P(B_i)P(A|B_i)$
设Ω为E的样本空间，A为E的事件，B1,B2,……,Bn互不相容，且P(Bi)>0， ，则
![图片标题](https://cdn.risingentropy.top/images/posts/ca70f14ab644127b9002313.png)
eg:袋中有5个球，2个黑球，3个白球，依次取两球，求第二次取到黑球的概率.
设B1表示“第一次取到黑球”的事件，B2表示“第一次取到白球”的事件，A 表示事件“第二次取黑球”由全概率公式有
$P(A) = P(A|B_1)P(B_1)+P(A|B_2)P(B_2)=\frac{2}{5}*\frac{1}{4}+\frac{3}{5}*\frac{1}{2} = \frac{2}{5}$
# 期望
如果X是一个离散的随机变量，输出值为 x1,x2, ...， 和输出值相应的概率为p1, p2, ... （概率和为1）, 那么期望值：
$$E(X) = \sum p_1x_i$$
# 期望的运算！！！
$E(φ)= ΣφiPi$，这是期望的定义，其中φi是一个取值，而Pi是取这个值的概率
Ø 期望有“线性”，也就是说对于不相关的两
个随机变量φ和ξ，$E(φ±ξ)=E(φ)±E(ξ)$；$E(φξ)=E(φ)E(ξ)$；$E(φ/ξ)=E(φ)/E(ξ)$
Ø 在某些情况下，期望可以表示成一个无穷的等比数列，然后利用极限的思想来求。
eg:扔掷一枚均匀的骰子，直到投出6为止，问平均需要扔掷几次？
设Xk为事件：第k次扔掷才投出6，则$P(Xk)=1/6*(5/6)^(k-1)$，
$P(k+1)=5/6*P(k)$
$E(X)=1P(1)+2P(2)+……+kP(k)+……=6$
# 全期望公式
$E(X)=E(E(Y|X))=\sum P(X=x_i)E(Y|X=x_i)$
eg:一项工作甲一个人完成，平均需要4小时，而乙有0.4的概率来帮忙，2个人完成平均需要3小时。用X表示完成工作的人数，Y表示完成这项工作的期望时间。则:

![图片标题](https://cdn.risingentropy.top/images/posts/ca70f14ab644127b9002313.png)
