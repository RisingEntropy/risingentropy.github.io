---
date: 2024-04-07 13:23:00 +0800
title: Tensor Decomposition Based Attention Module for Spiking Neural Networks
intro: Accepted by Knowledge-Based Systems
image: https://cdn.risingentropy.top/images/20240517193725.png
description: We design a plug-and-play attention module for spiking neural networks to apply attention in all spatial, channel and temporal dimensions using the tensor CP-decomposition. Networks equipped with our block reach SOTA performance in various tasks.
tags: [KBS, 2024, SNN, Tensor decomposition]
homepage: true
---
# Tensor Decomposition Based Attention Module for Spiking Neural Networks
<b>Haoyu Deng</b><sup>a</sup>, Ruijie Zhu<sup>b</sup>, Xuerui Qiu<sup>a</sup>, Yule Duanu<sup>a</sup>, Malu Zhang<sup>a,†</sup> and Liang-Jian Deng<sup>a,†</sup>
<sup>a</sup>University of Electronic Science and Technology of China, 611731, China
<sup>b</sup>University of California, Santa Cruz, 95064, United States
<sup>†</sup>Corresponding authors

This is the official repository for paper *Tensor Decomposition Based Attention Module for Spiking Neural Networks*. If you have any questions, feel free to raise an issue or send a mail to `academic@hydeng.cn`. I will respond to you as soon as possible.

paper:[[pdf](https://arxiv.org/pdf/2310.14576.pdf)] Code:[[Github](https://github.com/RisingEntropy/PFA)]
![img](https://cdn.risingentropy.top/images/20240517193725.png)


## Citation
If you think our work is useful, please give us a warm citation!
```
@article{DENG2024111780,
title = {Tensor decomposition based attention module for spiking neural networks},
journal = {Knowledge-Based Systems},
volume = {295},
pages = {111780},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111780},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124004143},
author = {Haoyu Deng and Ruijie Zhu and Xuerui Qiu and Yule Duan and Malu Zhang and Liang-Jian Deng},
keywords = {Spiking neural network, Attention mechanism, Tensor decomposition, Neuromorphic computing}
}
```
